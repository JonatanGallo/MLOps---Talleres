# ğŸ§ MLOps - Talleres Clasificador de PingÃ¼inos con MLflow

Este repositorio contiene el cÃ³digo usado para entrenar y desplegar un modelo de predicciÃ³n de clases de pingÃ¼inos basado en el dataset disponible en: [palmerpenguins](https://pypi.org/project/palmerpenguins/). El proyecto abarca desde la preparaciÃ³n de datos y el entrenamiento de modelos hasta el despliegue de una API REST para realizar predicciones, utilizando MLflow para el seguimiento de experimentos y gestiÃ³n del ciclo de vida de modelos.

---

## Arquitectura de Servicios

- **Servicio de PredicciÃ³n**: API REST con FastAPI para inferencia de modelos registrados en MLflow
- **MLflow Tracking Server**: Servidor de seguimiento de experimentos y registro de modelos
- **MinIO**: Almacenamiento de artefactos S3-compatible para modelos y datos
- **Jupyter Lab**: Entorno de experimentaciÃ³n interactivo con integraciÃ³n MLflow
- **Base de Datos MySQL**: Almacenamiento de metadatos de MLflow y datos de entrenamiento
- **Servicio de Entrenamiento**: AplicaciÃ³n Python para entrenamiento automatizado con logging a MLflow

### Componentes de MLflow

- **MLflow Tracking Server**: Servidor central para tracking de experimentos (puerto 8003)
- **MLflow Model Registry**: Registro centralizado de modelos con versionado y staging
- **MinIO S3 Storage**: Almacenamiento de artefactos de modelos y datasets (puerto 8000/8001)
- **MySQL Backend**: Base de datos para metadatos de experimentos y modelos
- **Jupyter Integration**: Notebooks con tracking automÃ¡tico de experimentos

## Entrenamiento de Modelos

### Workflow con MLflow Tracking

El entrenamiento de modelos utiliza MLflow para el seguimiento completo del ciclo de vida:

1. **PreparaciÃ³n de datos**: ETL con logging de datasets y mÃ©tricas de calidad
2. **Entrenamiento de modelos**: MÃºltiples algoritmos con tracking automÃ¡tico de parÃ¡metros y mÃ©tricas
3. **Registro de modelos**: Almacenamiento automÃ¡tico en MLflow Model Registry
4. **Versionado de modelos**: Control de versiones con staging (dev, staging, prod)

### CaracterÃ­sticas del Entrenamiento

- **Tracking automÃ¡tico**: Todos los experimentos se registran automÃ¡ticamente en MLflow
- **Soporte para mÃºltiples tipos de modelos** (Random Forest, SVM, Neural Network)
- **GestiÃ³n de artefactos**: Modelos y datasets almacenados en MinIO S3
- **ComparaciÃ³n de experimentos** a travÃ©s de la interfaz web de MLflow
- **Notebook interactivo** (Training.ipynb) con integraciÃ³n MLflow completa
- **Model Registry**: Registro centralizado con promociÃ³n de modelos entre stages

## Mejoras en la API

- **IntegraciÃ³n con MLflow Model Registry**: Carga dinÃ¡mica de modelos desde el registro
- **Endpoint para listado de modelos disponibles**: Consulta modelos registrados en MLflow
- **Sistema de normalizaciÃ³n de datos de entrada**: Preprocesamiento automÃ¡tico
- **Manejo de errores mejorado**: GestiÃ³n robusta de excepciones
- **DocumentaciÃ³n interactiva automÃ¡tica**: OpenAPI/Swagger integrado
- **SelecciÃ³n de modelo por stage**: Soporte para dev, staging y prod environments

## CreaciÃ³n del modelo

- El dataset se carga usando el mÃ©todo `load_penguins` expuesto en la librerÃ­a del proyecto `palmerpenguins`.  
- Se convierten columnas categÃ³ricas a numÃ©ricas usando One-shot Encoding.
- Se hace una escala para mantener la desviaciÃ³n estandar por debajo de 1.
- Se eliminan caracterÃ­sticas no representativas para los modelos(year).
---

## CaracterÃ­sticas principales

- ğŸ§ ETL completo para preparaciÃ³n de datos con logging en MLflow
- ğŸ¤– Entrenamiento de 3 modelos de ML diferentes con tracking automÃ¡tico
- ğŸš€ API REST con FastAPI para predicciones desde MLflow Model Registry
- ğŸ“¦ DockerizaciÃ³n con compose para despliegue multi-servicio
- ğŸ”„ Sistema dinÃ¡mico de selecciÃ³n de modelos por stage (dev/staging/prod)
- ğŸ“Š JupyterLab integrado con MLflow tracking automÃ¡tico
- ğŸ” Interfaz de documentaciÃ³n automÃ¡tica con OpenAPI
- ğŸ“ˆ **MLflow Tracking Server** para seguimiento completo de experimentos
- ğŸ—„ï¸ **MinIO S3 Storage** para almacenamiento de artefactos de modelos
- ğŸ“‹ **MLflow Model Registry** para gestiÃ³n del ciclo de vida de modelos
- ğŸ” **Interfaz web MLflow** para comparaciÃ³n y anÃ¡lisis de experimentos

---

## InstalaciÃ³n y configuraciÃ³n

Clonar el repositorio:

```bash
git clone https://github.com/JonatanGallo/MLOps---Talleres.git
cd penguins-taller-4-mlflow
```

## EjecuciÃ³n con Docker Compose

ConstrucciÃ³n y ejecuciÃ³n de todos los servicios:

```bash
docker-compose up
```

## Servicios desplegados: 

- **API de PredicciÃ³n**: http://localhost:8012
- **MLflow Tracking Server**: http://localhost:8003
- **MinIO Console**: http://localhost:8001 (usuario: admin, contraseÃ±a: supersecret)
- **MinIO API**: http://localhost:8000
- **Jupyter Lab**: http://localhost:8005 (token: cualquiera)
- **MySQL MLflow**: localhost:8004 (usuario: user, contraseÃ±a: password, base de datos: mlflow_db)
- **MySQL Training**: localhost:8006 (usuario: user, contraseÃ±a: password, base de datos: training)

## Entrenamiento de modelos

### Entrenamiento con MLflow Tracking

1. **Acceder a Jupyter Lab**: Abrir http://localhost:8005 en el navegador (token: cualquiera)
2. **Abrir notebook**: Navegar a `workspace/Training.ipynb`
3. **Ejecutar entrenamiento**: Ejecutar las celdas del notebook
4. **Monitorear en MLflow**: Ver experimentos en http://localhost:8003

### Entrenamiento ProgramÃ¡tico

Para entrenamiento desde cÃ³digo Python:

```python
# Ejemplo de entrenamiento con MLflow tracking
import mlflow
from etl import get_clean_data
from model import Model
from models import ModelType

# Configurar MLflow
mlflow.set_tracking_uri("http://localhost:8003")

# Entrenar modelo con tracking automÃ¡tico
X, y = get_clean_data()
with mlflow.start_run():
    model = Model(ModelType.RANDOM_FOREST)
    model.train(X, y)
    # El modelo se registra automÃ¡ticamente en MLflow
```
---

## Uso de la API


### 1. Acceder a la interfaz de documentaciÃ³n

Abrir en el navegador:  
[http://localhost:8012/docs](http://localhost:8012/docs)

---

## Uso de la API

### Listar modelos disponibles (desde MLflow Registry)

```bash
curl http://localhost:8012/models
```

Respuesta:

```json
{
  "available_models": [
    "penguin_random_forest",
    "penguin_svm", 
    "penguin_neural_network"
  ]
}
```
### Cargar un modelo especÃ­fico

```bash
curl http://localhost:8012/load_model/random_forest
```

### Predecir con modelo desde MLflow Registry (POST)

```bash
curl -X POST "http://localhost:8012/predict/penguin_random_forest" \
-H "Content-Type: application/json" \
-d '{
  "island": "Biscoe",
  "bill_length_mm": 50.0,
  "bill_depth_mm": 16.3,
  "flipper_length_mm": 230,
  "body_mass_g": 5700,
  "sex": "male",
  "year": 2007
}'
```

Respuesta:

```json
{
  "model_used": "penguin_random_forest",
  "prediction": "Gentoo"
}
```

### Predecir con modelo por stage

```bash
# Usar modelo en stage 'prod' (por defecto)
curl -X POST "http://localhost:8012/predict/penguin_random_forest" \
-H "Content-Type: application/json" \
-d '{...}'

# Para usar un stage especÃ­fico, configurar la variable MODEL_STAGE
# en el docker-compose.yaml: MODEL_STAGE=staging
```

---

## Estructura del proyecto

```
penguins-taller-4-mlflow/
â”œâ”€â”€ api/                         # Servicio de API de predicciÃ³n
â”‚   â”œâ”€â”€ main.py                  # AplicaciÃ³n FastAPI con integraciÃ³n MLflow
â”‚   â”œâ”€â”€ model.py                 # Clases de modelos ML
â”‚   â”œâ”€â”€ pyproject.toml          # ConfiguraciÃ³n de dependencias
â”‚   â”œâ”€â”€ scaler.pkl              # Scaler para normalizaciÃ³n
â”‚   â”œâ”€â”€ penguins.py             # DefiniciÃ³n de especies de pingÃ¼inos
â”‚   â”œâ”€â”€ uv.lock                 # Lock file de dependencias
â”‚   â”œâ”€â”€ ModelService.py          # Servicio para manejar modelos
â”‚   â”œâ”€â”€ Dockerfile              # Dockerfile para el servicio de API
â”‚   â””â”€â”€ dto/                    # Objetos de transferencia de datos
â”‚       â”œâ”€â”€ model_prediction_request.py
â”‚       â””â”€â”€ normalized_request.py
â”œâ”€â”€ training_app/               # Servicio de entrenamiento con MLflow
â”‚   â”œâ”€â”€ Training.ipynb          # Notebook de entrenamiento con MLflow tracking
â”‚   â”œâ”€â”€ etl.py                  # ExtracciÃ³n, transformaciÃ³n y carga
â”‚   â”œâ”€â”€ model.py                # DefiniciÃ³n de modelos de ML
â”‚   â”œâ”€â”€ models.py               # Tipos de modelos disponibles
â”‚   â”œâ”€â”€ train.py                # Script de entrenamiento con MLflow logging
â”‚   â”œâ”€â”€ db.py                   # ConexiÃ³n a base de datos
â”‚   â”œâ”€â”€ pyproject.toml          # ConfiguraciÃ³n de dependencias
â”‚   â”œâ”€â”€ uv.lock                 # Lock file de dependencias
â”‚   â”œâ”€â”€ Dockerfile              # Dockerfile para Jupyter con MLflow
â”‚   â”œâ”€â”€ requirements.txt        # Dependencias adicionales
â”‚   â”œâ”€â”€ scaler.pkl              # Scaler para normalizaciÃ³n
â”‚   â””â”€â”€ raw_data.csv            # Datos de entrenamiento
â”œâ”€â”€ mlflow/                     # ConfiguraciÃ³n de MLflow
â”‚   â””â”€â”€ Dockerfile              # Dockerfile personalizado de MLflow
â”œâ”€â”€ mlflowdb/                   # Directorio para base de datos MLflow
â”œâ”€â”€ notebooks/                  # Notebooks adicionales
â”‚   â””â”€â”€ Untitled.ipynb         # Notebook de ejemplo
â”œâ”€â”€ docker-compose.yaml         # OrquestaciÃ³n de servicios
â””â”€â”€ README.md                   
```

---

## Workflow de MLflow

El flujo de trabajo con MLflow automatiza el seguimiento completo del ciclo de vida de modelos:

### Componentes del Workflow

1. **Experiment Tracking** ğŸ“Š
   - Registro automÃ¡tico de parÃ¡metros, mÃ©tricas y artefactos
   - ComparaciÃ³n de mÃºltiples experimentos y runs
   - VisualizaciÃ³n de mÃ©tricas en tiempo real

2. **Model Registry** ğŸ“‹
   - Registro centralizado de modelos entrenados
   - Versionado automÃ¡tico de modelos
   - GestiÃ³n de stages (dev, staging, prod)

3. **Artifact Storage** ğŸ’¾
   - Almacenamiento de modelos en MinIO S3
   - Persistencia de datasets y scalers
   - Trazabilidad completa de artefactos

4. **Model Serving** ğŸš€
   - Carga dinÃ¡mica de modelos desde el registry
   - SelecciÃ³n de modelos por stage
   - API REST para inferencia

### Flujo de EjecuciÃ³n

```
Data Preparation â†’ Model Training â†’ MLflow Logging â†’ Model Registry â†’ API Serving
```

### CaracterÃ­sticas del Tracking

- **Automatic Logging**: ParÃ¡metros, mÃ©tricas y modelos se registran automÃ¡ticamente
- **Experiment Comparison**: Interfaz web para comparar mÃºltiples experimentos
- **Model Versioning**: Control de versiones automÃ¡tico en el registry
- **Stage Management**: PromociÃ³n de modelos entre dev, staging y prod

---

## Modelos implementados

- Random Forest - Clasificador de bosques aleatorios  
- SVM - MÃ¡quinas de Soporte Vectorial  
- Neural Network - Red neuronal multicapa  

---


## Especies de pingÃ¼inos soportadas

| Especie    | Valor numÃ©rico | DescripciÃ³n             |
|------------|----------------|-------------------------|
| Adelie     | 0              | PingÃ¼inos Adelia        |
| Chinstrap  | 1              | PingÃ¼inos de barbijo    |
| Gentoo     | 2              | PingÃ¼inos papÃºa         |

---
## Desarrollo

Para desarrollo y debugging:

- **Ejecutar servicios**: `docker-compose up` para iniciar todos los servicios
- **Monitorear MLflow**: Acceder a http://localhost:8003 para ver experimentos y modelos
- **Jupyter Lab**: Usar http://localhost:8005 para experimentaciÃ³n interactiva
- **MinIO Console**: Acceder a http://localhost:8001 para gestionar artefactos
- **Ver experimentos**: Comparar runs y mÃ©tricas en la interfaz web de MLflow
- **Modificar cÃ³digo**: Los cambios en `training_app/` se reflejan automÃ¡ticamente
- **Modelos**: Los modelos se almacenan automÃ¡ticamente en MinIO S3 y MLflow Registry
- **Base de datos**: Conectar a MySQL MLflow (8004) y Training (8006) para inspeccionar datos

---
## Notas de la versiÃ³n

- **MLflow Tracking**: Seguimiento completo de experimentos con mÃ©tricas y parÃ¡metros automÃ¡ticos
- **Model Registry**: Registro centralizado con versionado y gestiÃ³n de stages
- **MinIO S3**: Almacenamiento escalable de artefactos de modelos y datasets
- **API**: IntegraciÃ³n directa con MLflow Model Registry para serving dinÃ¡mico
- **Jupyter Integration**: Notebooks con tracking automÃ¡tico de experimentos MLflow
- **MySQL Backend**: Persistencia robusta de metadatos y datos de entrenamiento
- **Container Orchestration**: Docker Compose para despliegue multi-servicio

---

## Acceso a Servicios Web

| Servicio | URL | Credenciales |
|----------|-----|--------------|
| **API de PredicciÃ³n** | http://10.43.100.99:8012 | - |
| **MLflow UI** | http://10.43.100.99:8003 | - |
| **Jupyter Lab** | http://10.43.100.99:8005 | Token: `cualquiera` |
| **MinIO Console** | http://10.43.100.99:8001 | admin / supersecret |
| **API Docs** | http://10.43.100.99:8012/docs | - |

---

## MLflow Model Registry

Para gestionar modelos en diferentes stages:

1. **Registrar modelo**: Los modelos se registran automÃ¡ticamente durante el entrenamiento
2. **Promocionar modelo**: Usar la interfaz MLflow para mover modelos entre stages
3. **Usar en API**: La API carga automÃ¡ticamente modelos del stage configurado (prod por defecto)
