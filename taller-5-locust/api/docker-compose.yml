services:
  api:
    image: jdromero9402/mlops_talleres:inference
    ports:
      - "8005:8000"
    deploy:
      resources:
        limits:
          memory: 10G
          cpus: 2
    # restart: "no"
    # replicas: 1
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]