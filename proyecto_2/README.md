# ğŸŒ² MLOps - Talleres Clasificador de Cover Type

<div align="center">

![MLOps](https://img.shields.io/badge/MLOps-Machine%20Learning%20Operations-blue)
![Python](https://img.shields.io/badge/Python-3.9+-green)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)
![Airflow](https://img.shields.io/badge/Apache-Airflow-orange)
![MLflow](https://img.shields.io/badge/MLflow-Model%20Registry-purple)
![FastAPI](https://img.shields.io/badge/FastAPI-API%20Framework-teal)
![Gradio](https://img.shields.io/badge/Gradio-Web%20Interface-yellow)

</div>

Este repositorio contiene el cÃ³digo usado para entrenar y desplegar un modelo de predicciÃ³n de tipos de cobertura forestal basado en el dataset de Cover Type. El proyecto abarca desde la preparaciÃ³n de datos y el entrenamiento de modelos hasta el desplieque de una API REST y aplicaciÃ³n web para realizar predicciones, con integraciÃ³n completa de MLflow para gestiÃ³n de modelos.

---

## Arquitectura de Servicios

- **Servicio de PredicciÃ³n**: API REST con FastAPI para inferencia de modelos MLflow
- **Interfaz Web**: AplicaciÃ³n Gradio para predicciones interactivas
- **OrquestaciÃ³n de Workflows**: Apache Airflow para automatizaciÃ³n y programaciÃ³n de tareas de ML
- **Model Registry**: MLflow para gestiÃ³n y versionado de modelos
- **Almacenamiento de Objetos**: MinIO (S3-compatible) para artefactos de MLflow
- **Base de Datos de Entrenamiento**: MySQL para almacenamiento de datos de entrenamiento
- **Base de Datos MLflow**: MySQL para metadatos de experimentos y modelos
- **VolÃºmenes Compartidos**: Sistema de archivos compartido para modelos entrenados y logs

### Componentes de Airflow

- **Airflow Webserver**: Interfaz web para monitoreo y gestiÃ³n de DAGs (puerto 8080)
- **Airflow Scheduler**: Planificador de tareas que ejecuta los DAGs segÃºn su programaciÃ³n
- **Airflow Worker**: Ejecutor de tareas usando Celery
- **Airflow Triggerer**: Manejo de sensores y triggers asÃ­ncronos
- **PostgreSQL**: Base de datos de metadatos de Airflow
- **Redis**: Broker de mensajes para Celery

### Componentes de MLflow

- **MLflow Tracking Server**: Servidor para tracking de experimentos (puerto 8003)
- **MLflow Model Registry**: Registro centralizado de modelos con versionado
- **MinIO Storage**: Almacenamiento S3-compatible para artefactos (puerto 8000)
- **MySQL MLflow DB**: Base de datos para metadatos de MLflow (puerto 8004)

## Entrenamiento de Modelos

### Workflow Automatizado con Airflow + MLflow

El entrenamiento de modelos se ejecuta mediante un DAG (Directed Acyclic Graph) de Airflow que automatiza todo el proceso con integraciÃ³n completa de MLflow:

1. **check_run_count**: Verifica el nÃºmero de ejecuciones (mÃ¡ximo 11)
2. **branch_first_run**: Determina si es la primera ejecuciÃ³n
3. **clean_all_data**: Limpia datos anteriores de la base de datos (solo primera vez)
4. **store_raw_data**: Descarga y almacena datos frescos del dataset
5. **get_raw_data**: Extrae y procesa los datos para entrenamiento
6. **save_clean_data**: Guarda datos limpios para entrenamiento
7. **train_model**: Entrena modelo con MLflow y actualiza el alias de producciÃ³n

### CaracterÃ­sticas del Entrenamiento

- **AutomatizaciÃ³n completa**: El DAG se ejecuta cada 5 minutos y 20 segundos
- **IntegraciÃ³n MLflow**: Tracking automÃ¡tico de experimentos y mÃ©tricas
- **Model Registry**: GestiÃ³n centralizada de versiones de modelos
- **SelecciÃ³n automÃ¡tica**: El mejor modelo se promociona automÃ¡ticamente a producciÃ³n
- **Persistencia en S3**: Artefactos almacenados en MinIO (S3-compatible)
- **Monitoreo en tiempo real** a travÃ©s de las interfaces de Airflow y MLflow
- **Notebook interactivo** (TrainModels.ipynb) disponible para experimentaciÃ³n manual

## Mejoras en la API

- Endpoint para listado de modelos disponibles

- Sistema de normalizaciÃ³n de datos de entrada

- Manejo de errores mejorado

- DocumentaciÃ³n interactiva automÃ¡tica

## CreaciÃ³n del modelo

- El dataset se carga usando el mÃ©todo `load_penguins` expuesto en la librerÃ­a del proyecto `palmerpenguins`.  
- Se convierten columnas categÃ³ricas a numÃ©ricas usando One-shot Encoding.
- Se hace una escala para mantener la desviaciÃ³n estandar por debajo de 1.
- Se eliminan caracterÃ­sticas no representativas para los modelos(year).
---

## âœ¨ CaracterÃ­sticas principales

<div align="center">

| ğŸŒ² **ETL** | ğŸ¤– **ML** | ğŸš€ **API** | ğŸŒ **Web** |
|------------|-----------|------------|------------|
| PreparaciÃ³n de datos Cover Type | Random Forest + GridSearch | FastAPI + MLflow | Gradio interactivo |
| Transformaciones automÃ¡ticas | Tracking automÃ¡tico | DocumentaciÃ³n automÃ¡tica | Ejemplos predefinidos |

</div>

<div align="center">

| ğŸ“¦ **Infraestructura** | âš¡ **OrquestaciÃ³n** | ğŸ—„ï¸ **Almacenamiento** | ğŸ“ˆ **Monitoreo** |
|----------------------|-------------------|---------------------|------------------|
| Docker Compose | Apache Airflow | MinIO S3 | Interfaces web |
| Multi-servicio | DAGs automatizados | MySQL dual | Logs en tiempo real |
| Hot reload | Cada 5 minutos | Model Registry | MÃ©tricas MLflow |

</div>

---

## ğŸš€ InstalaciÃ³n y configuraciÃ³n

### ğŸ“‹ Prerrequisitos

<div align="center">

| ğŸ”§ **Requisito** | âœ… **DescripciÃ³n** |
|------------------|-------------------|
| **Docker** | Docker y Docker Compose instalados |
| **RAM** | Al menos 8GB de RAM disponible |
| **Puertos** | Puertos 8000-8012, 8080 disponibles |

</div>

### Clonar el repositorio

```bash
git clone https://github.com/JonatanGallo/MLOps---Talleres.git
cd MLOps---Talleres/proyecto_2
```

### EjecuciÃ³n con Docker Compose

ConstrucciÃ³n y ejecuciÃ³n de todos los servicios:

```bash
# Construir y ejecutar todos los servicios
docker-compose up --build

# Ejecutar en segundo plano
docker-compose up -d

# Ver logs de servicios especÃ­ficos
docker-compose logs -f airflow-webserver
docker-compose logs -f mlflow
docker-compose logs -f prediction
```

### VerificaciÃ³n de Servicios

Una vez iniciados los servicios, verificar que todos estÃ©n funcionando:

```bash
# Verificar estado de contenedores
docker-compose ps

# Verificar logs de servicios
docker-compose logs --tail=50
```

## Servicios desplegados

<div align="center">

| ğŸš€ **Servicio** | ğŸŒ **URL** | ğŸ”‘ **Credenciales** |
|----------------|------------|-------------------|
| **API de PredicciÃ³n** | http://10.43.100.102:8012 | - |
| **Interfaz Web Gradio** | http://10.43.100.102:8014 | - |
| **Airflow Webserver** | http://10.43.100.102:8080 | airflow / airflow |
| **MLflow Tracking Server** | http://10.43.100.102:8003 | - |
| **MinIO Console** | http://10.43.100.99:8000 | admin / supersecret |
| **MySQL Training DB** | http://10.43.100.86:8085 | user / password |
| **MySQL MLflow DB** | http://10.43.100.99:8004 | user / password |

</div>

## Entrenamiento de modelos

### Entrenamiento Automatizado con Airflow

1. **Acceder a Airflow**: Abrir http://10.43.100.102:8080 en el navegador
2. **Credenciales**: Usuario: `airflow`, ContraseÃ±a: `airflow`
3. **Ejecutar DAG**: Buscar el DAG `training_dag` y activarlo
4. **Monitorear**: Ver el progreso de las tareas en tiempo real

### Entrenamiento Manual (Opcional)

Para experimentaciÃ³n manual, se puede usar el notebook disponible:

```python
# Ejemplo de entrenamiento desde el notebook
from etl import get_data
from model import Model
from models import ModelType

X, y = get_data()
model = Model(ModelType.RANDOM_FOREST)
model.train(X, y)
model.save('/models/model_random_forest.pkl')
```
---

## ğŸ”— Uso de la API

### ğŸ“š 1. Acceder a la interfaz de documentaciÃ³n

<div align="center">

[![FastAPI Docs](https://img.shields.io/badge/FastAPI-Documentation-red?style=for-the-badge)](http://10.43.100.102:8012/docs)

</div>

### ğŸŒ 2. Interfaz Web con Gradio

<div align="center">

[![Gradio App](https://img.shields.io/badge/Gradio-Web%20Interface-yellow?style=for-the-badge)](http://10.43.100.102:8014)

</div>

---

## Uso de la API

### Listar modelos disponibles

```bash
curl http://10.43.100.102:8012/models
```

Respuesta:

```json
{
  "available_models": [
    "random_forest"
  ]
}
```

### Cargar un modelo especÃ­fico

```bash
curl http://10.43.100.102:8012/load_model/random_forest
```

### Predecir con modelo MLflow (POST)

```bash
curl -X POST "http://10.43.100.102:8012/predict" \
-H "Content-Type: application/json" \
-d '{
  "Elevation": 2358,
  "Aspect": 8,
  "Slope": 5,
  "Horizontal_Distance_To_Hydrology": 170,
  "Vertical_Distance_To_Hydrology": 19,
  "Horizontal_Distance_To_Roadways": 1354,
  "Hillshade_9am": 214,
  "Hillshade_Noon": 230,
  "Hillshade_3pm": 153,
  "Horizontal_Distance_To_Fire_Points": 342,
  "Wilderness_Area": "Cache",
  "Soil_Type": "C2717"
}'
```

Respuesta:

```json
{
  "prediction": 4
}
```

---

## Interfaz Web con Gradio

### AplicaciÃ³n Web Interactiva

El proyecto incluye una aplicaciÃ³n web desarrollada con Gradio que proporciona una interfaz amigable para realizar predicciones:

- **URL**: http://10.43.100.102:8014/
- **CaracterÃ­sticas**:
  - Interfaz intuitiva con formularios para entrada de datos
  - ValidaciÃ³n automÃ¡tica de campos de entrada
  - VisualizaciÃ³n en tiempo real de requests y responses
  - Ejemplos predefinidos para testing rÃ¡pido
  - IntegraciÃ³n directa con la API de predicciÃ³n

### Campos de Entrada

La aplicaciÃ³n Gradio incluye los siguientes campos para el dataset de Cover Type:

- **Elevation**: ElevaciÃ³n en metros
- **Aspect**: OrientaciÃ³n en grados
- **Slope**: Pendiente en grados
- **Horizontal_Distance_To_Hydrology**: Distancia horizontal a hidrologÃ­a
- **Vertical_Distance_To_Hydrology**: Distancia vertical a hidrologÃ­a
- **Horizontal_Distance_To_Roadways**: Distancia horizontal a carreteras
- **Hillshade_9am**: Sombreado a las 9 AM
- **Hillshade_Noon**: Sombreado al mediodÃ­a
- **Hillshade_3pm**: Sombreado a las 3 PM
- **Horizontal_Distance_To_Fire_Points**: Distancia horizontal a puntos de fuego
- **Wilderness_Area**: Ãrea silvestre (Rawah, Neota, Comanche, Cache)
- **Soil_Type**: Tipo de suelo (ej: C2717)

### Ejemplos Incluidos

La aplicaciÃ³n incluye ejemplos predefinidos para facilitar las pruebas:

```python
# Ejemplo 1: Cache wilderness area
[2358, 8, 5, 170, 19, 1354, 214, 230, 153, 342, "Cache", "C2717"]

# Ejemplo 2: Rawah wilderness area  
[2596, 51, 3, 258, 0, 510, 221, 232, 148, 6279, "Rawah", "C7744"]
```

---

## GestiÃ³n de Modelos con MLflow

### MLflow Tracking Server

El proyecto utiliza MLflow para el tracking de experimentos y gestiÃ³n de modelos:

- **URL**: http://10.43.100.99:8003
- **CaracterÃ­sticas**:
  - Tracking automÃ¡tico de experimentos y mÃ©tricas
  - Registro centralizado de modelos
  - Versionado automÃ¡tico de modelos
  - Almacenamiento de artefactos en MinIO (S3-compatible)
  - Interfaz web para monitoreo de experimentos

### Model Registry

El sistema incluye un registro de modelos con las siguientes caracterÃ­sticas:

- **Modelo Principal**: `random-forest-regressor`
- **Alias de ProducciÃ³n**: `prod` (modelo activo en producciÃ³n)
- **SelecciÃ³n AutomÃ¡tica**: El mejor modelo se promociona automÃ¡ticamente
- **MÃ©tricas de EvaluaciÃ³n**: `test_score` para comparaciÃ³n de versiones
- **Persistencia**: Modelos almacenados en MinIO S3

### ConfiguraciÃ³n de MLflow

```python
# ConfiguraciÃ³n del tracking URI
mlflow.set_tracking_uri("http://10.43.100.99:8003")

# ConfiguraciÃ³n del experimento
mlflow.set_experiment("random_forest_experiment")

# Autologging habilitado
mlflow.autolog(
    log_input_examples=True,
    log_model_signatures=True,
    log_models=True,
    log_datasets=True
)
```

### Almacenamiento de Artefactos

- **Backend Store**: MySQL (puerto 8004)
- **Artifact Store**: MinIO S3 (puerto 8000)
- **Bucket**: `mlflows/artifacts`
- **ConfiguraciÃ³n S3**:
  - Endpoint: `http://10.43.100.99:8000`
  - Access Key: `admin`
  - Secret Key: `supersecret`
  - Region: `us-east-1`

### Monitoreo de Experimentos

1. **Acceder a MLflow**: http://10.43.100.99:8003
2. **Ver Experimentos**: Navegar a la secciÃ³n "Experiments"
3. **Modelos Registrados**: Ir a "Models" para ver el registro
4. **MÃ©tricas**: Revisar mÃ©tricas de rendimiento en tiempo real
5. **Artefactos**: Descargar modelos y visualizaciones

---

## Estructura del proyecto

```
proyecto_2/
â”œâ”€â”€ api/                         # Servicio de API de predicciÃ³n
â”‚   â”œâ”€â”€ main.py                  # AplicaciÃ³n FastAPI principal con MLflow
â”‚   â”œâ”€â”€ model.py                 # DefiniciÃ³n de modelos de ML
â”‚   â”œâ”€â”€ ModelService.py          # Servicio para manejar modelos
â”‚   â”œâ”€â”€ penguins.py             # DefiniciÃ³n de especies de pingÃ¼inos
â”‚   â”œâ”€â”€ pyproject.toml          # ConfiguraciÃ³n de dependencias
â”‚   â”œâ”€â”€ uv.lock
â”‚   â”œâ”€â”€ scaler.pkl              # Scaler para normalizaciÃ³n
â”‚   â”œâ”€â”€ Dockerfile              # Dockerfile para el servicio de API
â”‚   â”œâ”€â”€ webApp/                 # AplicaciÃ³n web Gradio
â”‚   â”‚   â””â”€â”€ gradio_predict_app.py
â”‚   â””â”€â”€ dto/                    # Objetos de transferencia de datos
â”‚       â”œâ”€â”€ model_prediction_request.py
â”‚       â””â”€â”€ normalized_request.py
â”œâ”€â”€ training_app/               # Servicio de entrenamiento
â”‚   â”œâ”€â”€ TrainModels.ipynb       # Notebook de entrenamiento
â”‚   â”œâ”€â”€ etl.py                  # ExtracciÃ³n, transformaciÃ³n y carga
â”‚   â”œâ”€â”€ dataService.py          # Servicio de datos
â”‚   â”œâ”€â”€ model.py                # DefiniciÃ³n de modelos de ML
â”‚   â”œâ”€â”€ models.py               # Tipos de modelos disponibles
â”‚   â”œâ”€â”€ train.py                # Script de entrenamiento con MLflow
â”‚   â”œâ”€â”€ db.py                   # ConexiÃ³n a base de datos
â”‚   â”œâ”€â”€ pyproject.toml          # ConfiguraciÃ³n de dependencias
â”‚   â”œâ”€â”€ uv.lock
â”‚   â”œâ”€â”€ Dockerfile              # Dockerfile para el servicio de entrenamiento
â”‚   â””â”€â”€ raw_data.csv            # Datos de entrenamiento
â”œâ”€â”€ dags/                       # DAGs de Airflow
â”‚   â”œâ”€â”€ training.py             # DAG principal de entrenamiento
â”‚   â”œâ”€â”€ example_dag.py          # DAG de ejemplo
â”‚   â”œâ”€â”€ example_2.py            # DAG de ejemplo adicional
â”‚   â””â”€â”€ training_app/           # MÃ³dulos compartidos con el DAG
â”œâ”€â”€ airflow/                    # ConfiguraciÃ³n de Airflow
â”‚   â”œâ”€â”€ Dockerfile              # Dockerfile personalizado de Airflow
â”‚   â”œâ”€â”€ Dockerfile.fb           # Dockerfile alternativo
â”‚   â””â”€â”€ requirements.txt        # Dependencias adicionales
â”œâ”€â”€ mlflow/                     # ConfiguraciÃ³n de MLflow
â”‚   â””â”€â”€ Dockerfile              # Dockerfile para servidor MLflow
â”œâ”€â”€ models/                     # Modelos entrenados (volumen compartido)
â”‚   â”œâ”€â”€ model_neural_network.pkl
â”‚   â”œâ”€â”€ model_random_forest.pkl
â”‚   â””â”€â”€ model_svm.pkl
â”œâ”€â”€ logs/                       # Logs de Airflow
â”œâ”€â”€ plugins/                    # Plugins personalizados de Airflow
â”œâ”€â”€ mlflowdb/                   # Base de datos MLflow (volumen)
â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n de servicios
â”œâ”€â”€ docker-compose.yml.bk       # Backup del compose
â”œâ”€â”€ arquitecturaAirflow.drawio.svg # Diagrama de arquitectura
â””â”€â”€ README.md                   
```

---

## Workflow del DAG de Entrenamiento

El DAG `training_dag` automatiza el proceso completo de entrenamiento de modelos con integraciÃ³n MLflow:

### Tareas del DAG

1. **check_run_count** ğŸ”¢
   - Verifica el nÃºmero de ejecuciones (mÃ¡ximo 11)
   - Incrementa el contador de ejecuciones

2. **branch_first_run** ğŸŒ¿
   - Determina si es la primera ejecuciÃ³n del DAG
   - Dirige el flujo segÃºn el estado inicial

3. **clean_all_data** ğŸ—‘ï¸ (solo primera vez)
   - Limpia datos anteriores de la base de datos MySQL
   - Prepara el entorno para nuevos datos

4. **store_raw_data** ğŸ“¥
   - Descarga el dataset desde la fuente
   - Almacena los datos en la base de datos MySQL

5. **get_raw_data** ğŸ”„
   - Extrae datos de la base de datos
   - Aplica transformaciones ETL bÃ¡sicas

6. **save_clean_data** ğŸ’¾
   - Guarda datos limpios para entrenamiento
   - Prepara datos finales para el modelo

7. **train_model** ğŸ¤–
   - Entrena modelo Random Forest con GridSearch
   - Registra experimento en MLflow
   - Promociona mejor modelo a producciÃ³n automÃ¡ticamente

8. **mark_done** âœ…
   - Marca la primera ejecuciÃ³n como completada

9. **pause_dag_if_failed** â¸ï¸
   - Pausa el DAG si alguna tarea falla

### Flujo de EjecuciÃ³n

```
check_run_count â†’ branch_first_run â†’ [clean_all_data | skip_first_time] â†’ 
join_after_branch â†’ mark_done â†’ store_raw_data â†’ get_raw_data â†’ 
save_clean_data â†’ train_model â†’ pause_dag_if_failed
```

### ProgramaciÃ³n

- **Schedule**: `timedelta(minutes=5, seconds=20)` (cada 5 minutos y 20 segundos)
- **Start Date**: 2025-10-03
- **Max Active Runs**: 11
- **Catchup**: False

---

## Modelos implementados

- **Random Forest** - Clasificador de bosques aleatorios con GridSearch
- **MLflow Integration** - Tracking automÃ¡tico y versionado de modelos
- **Model Registry** - GestiÃ³n centralizada con alias de producciÃ³n

---

## Dataset de Cover Type

El proyecto utiliza el dataset de Cover Type para clasificaciÃ³n forestal:

### CaracterÃ­sticas del Dataset

- **Elevation**: ElevaciÃ³n en metros
- **Aspect**: OrientaciÃ³n en grados (0-360)
- **Slope**: Pendiente en grados
- **Horizontal_Distance_To_Hydrology**: Distancia horizontal a hidrologÃ­a
- **Vertical_Distance_To_Hydrology**: Distancia vertical a hidrologÃ­a
- **Horizontal_Distance_To_Roadways**: Distancia horizontal a carreteras
- **Hillshade_9am**: Sombreado a las 9 AM (0-255)
- **Hillshade_Noon**: Sombreado al mediodÃ­a (0-255)
- **Hillshade_3pm**: Sombreado a las 3 PM (0-255)
- **Horizontal_Distance_To_Fire_Points**: Distancia horizontal a puntos de fuego
- **Wilderness_Area**: Ãrea silvestre (Rawah, Neota, Comanche, Cache)
- **Soil_Type**: Tipo de suelo (40 tipos diferentes)

### Clases de Cover Type

| Clase | Valor numÃ©rico | DescripciÃ³n             |
|-------|----------------|-------------------------|
| 1     | 1              | Spruce/Fir              |
| 2     | 2              | Lodgepole Pine          |
| 3     | 3              | Ponderosa Pine          |
| 4     | 4              | Cottonwood/Willow       |
| 5     | 5              | Aspen                   |
| 6     | 6              | Douglas-fir             |
| 7     | 7              | Krummholz               |

---
## Desarrollo

Para desarrollo y debugging:

- **Ejecutar servicios**: `docker-compose up --build` para iniciar todos los servicios
- **Monitorear Airflow**: Acceder a 
**URL**: http://10.43.100.102:8080 (usuario: airflow, contraseÃ±a: airflow)
- **Monitorear MLflow**: Acceder a **URL**: http://10.43.100.99:8003/ para ver experimentos
- **Interfaz Gradio**: Acceder a http://10.43.100.102:8014 para predicciones interactivas
- **MinIO Console**: Acceder a http://10.43.100.99:8000 (admin/supersecret) para artefactos
- **Ejecutar DAGs**: El DAG `training_dag` se ejecuta automÃ¡ticamente cada 5 minutos
- **Ver logs**: Monitorear el progreso de las tareas en tiempo real
- **Modificar cÃ³digo**: Los cambios se reflejan automÃ¡ticamente con hot reload
- **Modelos**: Los modelos se almacenan en MLflow y MinIO
- **Base de datos**: Conectar a MySQL en 10.43.100.86:8005 (training) y http://10.43.100.99:8004 (mlflow)

---
## Notas de la versiÃ³n

- **MLflow Integration**: Tracking automÃ¡tico de experimentos y gestiÃ³n de modelos
- **Model Registry**: Sistema centralizado de versionado con alias de producciÃ³n
- **MinIO Storage**: Almacenamiento S3-compatible para artefactos de MLflow
- **Gradio Interface**: AplicaciÃ³n web interactiva para predicciones
- **Airflow**: OrquestaciÃ³n completa con DAGs automatizados cada 5 minutos
- **Base de datos**: MySQL dual para datos de entrenamiento y metadatos MLflow
- **API**: Servicio FastAPI con integraciÃ³n MLflow para predicciones
- **AutomatizaciÃ³n**: Entrenamiento y promociÃ³n automÃ¡tica de modelos
- **Monitoreo**: Interfaces web para Airflow, MLflow, MinIO y Gradio

---

## GuÃ­a para Capturas de Pantalla

Para documentar que todo funciona correctamente, sigue esta guÃ­a para tomar capturas de pantalla de todos los componentes:

### 1. VerificaciÃ³n de Servicios Docker

```bash
# Captura del estado de contenedores
docker-compose ps
```

**Servicios de Docker Compose ejecutÃ¡ndose**

<div align="center">
  <img src="./imgs/dockerAll.png" alt="Docker Services Status" width="800" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

### 2. Airflow Webserver

**URL**: http://10.43.100.102:8080  
**Credenciales**: airflow / airflow

#### ğŸ“‹ PÃ¡gina principal de Airflow con DAGs listados
<div align="center">
  <img src="./imgs/airflowMainPage.png" alt="Airflow Main Page" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ”„ DAG `training_dag` activo y ejecutÃ¡ndose
<div align="center">
  <img src="./imgs/DAGRunning.png" alt="DAG Running" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ“Š Vista de tareas del DAG con estados (success/failed)
<div align="center">
  <img src="./imgs/DAGTasks.png" alt="DAG Tasks" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ“ Logs de la tarea train_model
<div align="center">
  <img src="./imgs/TaskLog.png" alt="Task Logs" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

### 3. MLflow Tracking Server

**URL**: http://10.43.100.99:8003/

#### ğŸ  PÃ¡gina principal de MLflow
<div align="center">
  <img src="./imgs/mlMain.png" alt="MLflow Main Page" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ§ª SecciÃ³n "Experiments" mostrando `random_forest_experiment`
<div align="center">
  <img src="./imgs/mlExperiment.png" alt="MLflow Experiments" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ“ˆ Vista de runs con mÃ©tricas y parÃ¡metros
<div align="center">
  <img src="./imgs/mlStatistics.png" alt="MLflow Statistics" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ¤– SecciÃ³n "Models" mostrando `random-forest-regressor`
<div align="center">
  <img src="./imgs/mlModels.png" alt="MLflow Models" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ¯ Detalles del modelo con alias "prod"
<div align="center">
  <img src="./imgs/mlProd.png" alt="MLflow Production Model" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

### 4. MinIO Console

**URL**: http://10.43.100.99:8000  
**Credenciales**: admin / supersecret

#### ğŸª Dashboard principal de MinIO
<div align="center">
  <img src="./imgs/Minioinicio.png" alt="MinIO Dashboard" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ“¦ Bucket `mlflows` con artefactos almacenados
<div align="center">
  <img src="./imgs/Minioartefactos.png" alt="MinIO Artifacts" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ—‚ï¸ Contenido del bucket mostrando modelos y logs
<div align="center">
  <img src="./imgs/MinioBuckets.png" alt="MinIO Buckets" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

### 5. API de PredicciÃ³n

**URL**: http://10.43.100.102:8012

#### ğŸ“š DocumentaciÃ³n automÃ¡tica en `/docs`
<div align="center">
  <img src="./imgs/apiDocs.png" alt="API Documentation" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ”® Endpoint `/predict` con ejemplo de request/response
<div align="center">
  <img src="./imgs/apiPredict.png" alt="API Prediction" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

### 6. AplicaciÃ³n Web Gradio

**URL**: http://10.43.100.102:8014

#### ğŸŒ Interfaz principal con formularios
<div align="center">
  <img src="./imgs/gradio.png" alt="Gradio Interface" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ¯ Ejemplo de predicciÃ³n con datos de entrada
<div align="center">
  <img src="./imgs/predictGradio.png" alt="Gradio Prediction" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ“‹ SecciÃ³n de ejemplos predefinidos
<div align="center">
  <img src="./imgs/gradioExamples.png" alt="Gradio Examples" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>


### 7. Base de Datos MySQL

**ConexiÃ³n**: 10.43.100.86:8005 (training) y http://10.43.100.99:8004 (mlflow)


### 8. Logs del Sistema

```bash
# Logs de Airflow
docker-compose logs airflow-webserver

# Logs de MLflow
docker-compose logs mlflow

# Logs de API
docker-compose logs prediction
```

#### ğŸ“Š Logs de Airflow mostrando ejecuciÃ³n de DAG
<div align="center">
  <img src="./imgs/afLogs.png" alt="Airflow Logs" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸ”¬ Logs de MLflow mostrando tracking de experimentos
<div align="center">
  <img src="./imgs/mlLogs.png" alt="MLflow Logs" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

#### ğŸš€ Logs de API mostrando requests de predicciÃ³n
<div align="center">
  <img src="./imgs/apiLogs.png" alt="API Logs" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

### 9. Flujo Completo de PredicciÃ³n

#### ğŸ”„ DAG ejecutÃ¡ndose en Airflow
<div align="center">
  <img src="./imgs/dagRun.png" alt="DAG Running" width="900" style="border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
</div>

> ğŸ“ **Nota**: Las siguientes capturas de pantalla muestran el flujo completo del sistema:
> 1. âœ… DAG ejecutÃ¡ndose en Airflow (mostrado arriba)
> 2. ğŸ¤– Modelo entrenado en MLflow (ver secciÃ³n MLflow)
> 3. ğŸ”® PredicciÃ³n exitosa en API (ver secciÃ³n API)
> 4. ğŸŒ Interfaz Gradio funcionando (ver secciÃ³n Gradio)
> 5. ğŸ—„ï¸ Datos almacenados en MySQL (ver secciÃ³n Base de Datos)


---

### ğŸ† Contribuciones

Â¡Las contribuciones son bienvenidas! Por favor:

1. ğŸ´ Fork el proyecto
2. ğŸŒ¿ Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. ğŸ’¾ Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. ğŸ“¤ Push a la rama (`git push origin feature/AmazingFeature`)
5. ğŸ”„ Abre un Pull Request

---

### ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

---

<div align="center">

**â­ Si este proyecto te fue Ãºtil, Â¡dale una estrella! â­**

</div>

</div>


