# üå≤ MLOps - Talleres Clasificador de Cover Type

Este repositorio contiene el c√≥digo usado para entrenar y desplegar un modelo de predicci√≥n de tipos de cobertura forestal basado en el dataset de Cover Type. El proyecto abarca desde la preparaci√≥n de datos y el entrenamiento de modelos hasta el desplieque de una API REST y aplicaci√≥n web para realizar predicciones, con integraci√≥n completa de MLflow para gesti√≥n de modelos.

---

## Arquitectura de Servicios

- **Servicio de Predicci√≥n**: API REST con FastAPI para inferencia de modelos MLflow
- **Interfaz Web**: Aplicaci√≥n Gradio para predicciones interactivas
- **Orquestaci√≥n de Workflows**: Apache Airflow para automatizaci√≥n y programaci√≥n de tareas de ML
- **Model Registry**: MLflow para gesti√≥n y versionado de modelos
- **Almacenamiento de Objetos**: MinIO (S3-compatible) para artefactos de MLflow
- **Base de Datos de Entrenamiento**: MySQL para almacenamiento de datos de entrenamiento
- **Base de Datos MLflow**: MySQL para metadatos de experimentos y modelos
- **Vol√∫menes Compartidos**: Sistema de archivos compartido para modelos entrenados y logs

### Componentes de Airflow

- **Airflow Webserver**: Interfaz web para monitoreo y gesti√≥n de DAGs (puerto 8080)
- **Airflow Scheduler**: Planificador de tareas que ejecuta los DAGs seg√∫n su programaci√≥n
- **Airflow Worker**: Ejecutor de tareas usando Celery
- **Airflow Triggerer**: Manejo de sensores y triggers as√≠ncronos
- **PostgreSQL**: Base de datos de metadatos de Airflow
- **Redis**: Broker de mensajes para Celery

### Componentes de MLflow

- **MLflow Tracking Server**: Servidor para tracking de experimentos (puerto 8003)
- **MLflow Model Registry**: Registro centralizado de modelos con versionado
- **MinIO Storage**: Almacenamiento S3-compatible para artefactos (puerto 8000)
- **MySQL MLflow DB**: Base de datos para metadatos de MLflow (puerto 8004)

## Entrenamiento de Modelos

### Workflow Automatizado con Airflow + MLflow

El entrenamiento de modelos se ejecuta mediante un DAG (Directed Acyclic Graph) de Airflow que automatiza todo el proceso con integraci√≥n completa de MLflow:

1. **check_run_count**: Verifica el n√∫mero de ejecuciones (m√°ximo 11)
2. **branch_first_run**: Determina si es la primera ejecuci√≥n
3. **clean_all_data**: Limpia datos anteriores de la base de datos (solo primera vez)
4. **store_raw_data**: Descarga y almacena datos frescos del dataset
5. **get_raw_data**: Extrae y procesa los datos para entrenamiento
6. **save_clean_data**: Guarda datos limpios para entrenamiento
7. **train_model**: Entrena modelo con MLflow y actualiza el alias de producci√≥n

### Caracter√≠sticas del Entrenamiento

- **Automatizaci√≥n completa**: El DAG se ejecuta cada 5 minutos y 20 segundos
- **Integraci√≥n MLflow**: Tracking autom√°tico de experimentos y m√©tricas
- **Model Registry**: Gesti√≥n centralizada de versiones de modelos
- **Selecci√≥n autom√°tica**: El mejor modelo se promociona autom√°ticamente a producci√≥n
- **Persistencia en S3**: Artefactos almacenados en MinIO (S3-compatible)
- **Monitoreo en tiempo real** a trav√©s de las interfaces de Airflow y MLflow
- **Notebook interactivo** (TrainModels.ipynb) disponible para experimentaci√≥n manual

## Mejoras en la API

- Endpoint para listado de modelos disponibles

- Sistema de normalizaci√≥n de datos de entrada

- Manejo de errores mejorado

- Documentaci√≥n interactiva autom√°tica

## Creaci√≥n del modelo

- El dataset se carga usando el m√©todo `load_penguins` expuesto en la librer√≠a del proyecto `palmerpenguins`.  
- Se convierten columnas categ√≥ricas a num√©ricas usando One-shot Encoding.
- Se hace una escala para mantener la desviaci√≥n estandar por debajo de 1.
- Se eliminan caracter√≠sticas no representativas para los modelos(year).
---

## Caracter√≠sticas principales

- üå≤ ETL completo para preparaci√≥n de datos de Cover Type
- ü§ñ Entrenamiento automatizado con Random Forest y GridSearch
- üöÄ API REST con FastAPI para predicciones MLflow
- üåê Aplicaci√≥n web Gradio para predicciones interactivas
- üì¶ Dockerizaci√≥n completa con compose para despliegue multi-servicio
- üîÑ Sistema de versionado autom√°tico de modelos con MLflow
- üìä Notebook Jupyter integrado para experimentaci√≥n
- üîç Interfaz de documentaci√≥n autom√°tica
- ‚ö° **Orquestaci√≥n con Apache Airflow** para automatizaci√≥n de workflows
- üóÑÔ∏è **Bases de datos MySQL duales** para datos y metadatos MLflow
- üìà **Monitoreo en tiempo real** con interfaces web m√∫ltiples
- üè™ **Almacenamiento S3** con MinIO para artefactos de MLflow
- üéØ **Model Registry** con promoci√≥n autom√°tica a producci√≥n

---

## Instalaci√≥n y configuraci√≥n

### Prerrequisitos

- Docker y Docker Compose instalados
- Al menos 8GB de RAM disponible
- Puertos 8000-8012, 8080 disponibles

### Clonar el repositorio

```bash
git clone https://github.com/JonatanGallo/MLOps---Talleres.git
cd MLOps---Talleres/proyecto_2
```

### Ejecuci√≥n con Docker Compose

Construcci√≥n y ejecuci√≥n de todos los servicios:

```bash
# Construir y ejecutar todos los servicios
docker-compose up --build

# Ejecutar en segundo plano
docker-compose up -d

# Ver logs de servicios espec√≠ficos
docker-compose logs -f airflow-webserver
docker-compose logs -f mlflow
docker-compose logs -f prediction
```

### Verificaci√≥n de Servicios

Una vez iniciados los servicios, verificar que todos est√©n funcionando:

```bash
# Verificar estado de contenedores
docker-compose ps

# Verificar logs de servicios
docker-compose logs --tail=50
```

## Servicios desplegados: 

- **API de Predicci√≥n**: http://10.43.100.102:8012
- **Interfaz Web Gradio**: http://10.43.100.102:8014 (aplicaci√≥n web interactiva)
- **Airflow Webserver**: http://10.43.100.102:8080 (usuario: airflow, contrase√±a: airflow)
- **MLflow Tracking Server**: http://10.43.100.102:8003 (interfaz de experimentos y modelos)
- **MinIO Console**: http://10.43.100.99:8000 (usuario: admin, contrase√±a: supersecret)
- **MySQL Training DB**: http://10.43.100.86:8085 (usuario: user, contrase√±a: password, base de datos: training)
- **MySQL MLflow DB**: http://10.43.100.99:8004 (usuario: user, contrase√±a: password, base de datos: mlflow_db)

## Entrenamiento de modelos

### Entrenamiento Automatizado con Airflow

1. **Acceder a Airflow**: Abrir http://10.43.100.102:8080 en el navegador
2. **Credenciales**: Usuario: `airflow`, Contrase√±a: `airflow`
3. **Ejecutar DAG**: Buscar el DAG `training_dag` y activarlo
4. **Monitorear**: Ver el progreso de las tareas en tiempo real

### Entrenamiento Manual (Opcional)

Para experimentaci√≥n manual, se puede usar el notebook disponible:

```python
# Ejemplo de entrenamiento desde el notebook
from etl import get_data
from model import Model
from models import ModelType

X, y = get_data()
model = Model(ModelType.RANDOM_FOREST)
model.train(X, y)
model.save('/models/model_random_forest.pkl')
```
---

## Uso de la API

### 1. Acceder a la interfaz de documentaci√≥n

Abrir en el navegador:  
[http://10.43.100.102:8012/docs](http://10.43.100.102:8012/docs)

### 2. Interfaz Web con Gradio

Para predicciones interactivas, usar la aplicaci√≥n web Gradio:
[http://10.43.100.102:8014](http://10.43.100.102:8014)

---

## Uso de la API

### Listar modelos disponibles

```bash
curl http://10.43.100.102:8012/models
```

Respuesta:

```json
{
  "available_models": [
    "random_forest"
  ]
}
```

### Cargar un modelo espec√≠fico

```bash
curl http://10.43.100.102:8012/load_model/random_forest
```

### Predecir con modelo MLflow (POST)

```bash
curl -X POST "http://10.43.100.102:8012/predict" \
-H "Content-Type: application/json" \
-d '{
  "Elevation": 2358,
  "Aspect": 8,
  "Slope": 5,
  "Horizontal_Distance_To_Hydrology": 170,
  "Vertical_Distance_To_Hydrology": 19,
  "Horizontal_Distance_To_Roadways": 1354,
  "Hillshade_9am": 214,
  "Hillshade_Noon": 230,
  "Hillshade_3pm": 153,
  "Horizontal_Distance_To_Fire_Points": 342,
  "Wilderness_Area": "Cache",
  "Soil_Type": "C2717"
}'
```

Respuesta:

```json
{
  "prediction": 4
}
```

---

## Interfaz Web con Gradio

### Aplicaci√≥n Web Interactiva

El proyecto incluye una aplicaci√≥n web desarrollada con Gradio que proporciona una interfaz amigable para realizar predicciones:

- **URL**: http://10.43.100.102:8014/
- **Caracter√≠sticas**:
  - Interfaz intuitiva con formularios para entrada de datos
  - Validaci√≥n autom√°tica de campos de entrada
  - Visualizaci√≥n en tiempo real de requests y responses
  - Ejemplos predefinidos para testing r√°pido
  - Integraci√≥n directa con la API de predicci√≥n

### Campos de Entrada

La aplicaci√≥n Gradio incluye los siguientes campos para el dataset de Cover Type:

- **Elevation**: Elevaci√≥n en metros
- **Aspect**: Orientaci√≥n en grados
- **Slope**: Pendiente en grados
- **Horizontal_Distance_To_Hydrology**: Distancia horizontal a hidrolog√≠a
- **Vertical_Distance_To_Hydrology**: Distancia vertical a hidrolog√≠a
- **Horizontal_Distance_To_Roadways**: Distancia horizontal a carreteras
- **Hillshade_9am**: Sombreado a las 9 AM
- **Hillshade_Noon**: Sombreado al mediod√≠a
- **Hillshade_3pm**: Sombreado a las 3 PM
- **Horizontal_Distance_To_Fire_Points**: Distancia horizontal a puntos de fuego
- **Wilderness_Area**: √Årea silvestre (Rawah, Neota, Comanche, Cache)
- **Soil_Type**: Tipo de suelo (ej: C2717)

### Ejemplos Incluidos

La aplicaci√≥n incluye ejemplos predefinidos para facilitar las pruebas:

```python
# Ejemplo 1: Cache wilderness area
[2358, 8, 5, 170, 19, 1354, 214, 230, 153, 342, "Cache", "C2717"]

# Ejemplo 2: Rawah wilderness area  
[2596, 51, 3, 258, 0, 510, 221, 232, 148, 6279, "Rawah", "C7744"]
```

---

## Gesti√≥n de Modelos con MLflow

### MLflow Tracking Server

El proyecto utiliza MLflow para el tracking de experimentos y gesti√≥n de modelos:

- **URL**: http://10.43.100.99:8003
- **Caracter√≠sticas**:
  - Tracking autom√°tico de experimentos y m√©tricas
  - Registro centralizado de modelos
  - Versionado autom√°tico de modelos
  - Almacenamiento de artefactos en MinIO (S3-compatible)
  - Interfaz web para monitoreo de experimentos

### Model Registry

El sistema incluye un registro de modelos con las siguientes caracter√≠sticas:

- **Modelo Principal**: `random-forest-regressor`
- **Alias de Producci√≥n**: `prod` (modelo activo en producci√≥n)
- **Selecci√≥n Autom√°tica**: El mejor modelo se promociona autom√°ticamente
- **M√©tricas de Evaluaci√≥n**: `test_score` para comparaci√≥n de versiones
- **Persistencia**: Modelos almacenados en MinIO S3

### Configuraci√≥n de MLflow

```python
# Configuraci√≥n del tracking URI
mlflow.set_tracking_uri("http://10.43.100.99:8003")

# Configuraci√≥n del experimento
mlflow.set_experiment("random_forest_experiment")

# Autologging habilitado
mlflow.autolog(
    log_input_examples=True,
    log_model_signatures=True,
    log_models=True,
    log_datasets=True
)
```

### Almacenamiento de Artefactos

- **Backend Store**: MySQL (puerto 8004)
- **Artifact Store**: MinIO S3 (puerto 8000)
- **Bucket**: `mlflows/artifacts`
- **Configuraci√≥n S3**:
  - Endpoint: `http://10.43.100.99:8000`
  - Access Key: `admin`
  - Secret Key: `supersecret`
  - Region: `us-east-1`

### Monitoreo de Experimentos

1. **Acceder a MLflow**: http://10.43.100.99:8003
2. **Ver Experimentos**: Navegar a la secci√≥n "Experiments"
3. **Modelos Registrados**: Ir a "Models" para ver el registro
4. **M√©tricas**: Revisar m√©tricas de rendimiento en tiempo real
5. **Artefactos**: Descargar modelos y visualizaciones

---

## Estructura del proyecto

```
proyecto_2/
‚îú‚îÄ‚îÄ api/                         # Servicio de API de predicci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # Aplicaci√≥n FastAPI principal con MLflow
‚îÇ   ‚îú‚îÄ‚îÄ model.py                 # Definici√≥n de modelos de ML
‚îÇ   ‚îú‚îÄ‚îÄ ModelService.py          # Servicio para manejar modelos
‚îÇ   ‚îú‚îÄ‚îÄ penguins.py             # Definici√≥n de especies de ping√ºinos
‚îÇ   ‚îú‚îÄ‚îÄ pyproject.toml          # Configuraci√≥n de dependencias
‚îÇ   ‚îú‚îÄ‚îÄ uv.lock
‚îÇ   ‚îú‚îÄ‚îÄ scaler.pkl              # Scaler para normalizaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile              # Dockerfile para el servicio de API
‚îÇ   ‚îú‚îÄ‚îÄ webApp/                 # Aplicaci√≥n web Gradio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gradio_predict_app.py
‚îÇ   ‚îî‚îÄ‚îÄ dto/                    # Objetos de transferencia de datos
‚îÇ       ‚îú‚îÄ‚îÄ model_prediction_request.py
‚îÇ       ‚îî‚îÄ‚îÄ normalized_request.py
‚îú‚îÄ‚îÄ training_app/               # Servicio de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ TrainModels.ipynb       # Notebook de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ etl.py                  # Extracci√≥n, transformaci√≥n y carga
‚îÇ   ‚îú‚îÄ‚îÄ dataService.py          # Servicio de datos
‚îÇ   ‚îú‚îÄ‚îÄ model.py                # Definici√≥n de modelos de ML
‚îÇ   ‚îú‚îÄ‚îÄ models.py               # Tipos de modelos disponibles
‚îÇ   ‚îú‚îÄ‚îÄ train.py                # Script de entrenamiento con MLflow
‚îÇ   ‚îú‚îÄ‚îÄ db.py                   # Conexi√≥n a base de datos
‚îÇ   ‚îú‚îÄ‚îÄ pyproject.toml          # Configuraci√≥n de dependencias
‚îÇ   ‚îú‚îÄ‚îÄ uv.lock
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile              # Dockerfile para el servicio de entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ raw_data.csv            # Datos de entrenamiento
‚îú‚îÄ‚îÄ dags/                       # DAGs de Airflow
‚îÇ   ‚îú‚îÄ‚îÄ training.py             # DAG principal de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ example_dag.py          # DAG de ejemplo
‚îÇ   ‚îú‚îÄ‚îÄ example_2.py            # DAG de ejemplo adicional
‚îÇ   ‚îî‚îÄ‚îÄ training_app/           # M√≥dulos compartidos con el DAG
‚îú‚îÄ‚îÄ airflow/                    # Configuraci√≥n de Airflow
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile              # Dockerfile personalizado de Airflow
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.fb           # Dockerfile alternativo
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt        # Dependencias adicionales
‚îú‚îÄ‚îÄ mlflow/                     # Configuraci√≥n de MLflow
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile              # Dockerfile para servidor MLflow
‚îú‚îÄ‚îÄ models/                     # Modelos entrenados (volumen compartido)
‚îÇ   ‚îú‚îÄ‚îÄ model_neural_network.pkl
‚îÇ   ‚îú‚îÄ‚îÄ model_random_forest.pkl
‚îÇ   ‚îî‚îÄ‚îÄ model_svm.pkl
‚îú‚îÄ‚îÄ logs/                       # Logs de Airflow
‚îú‚îÄ‚îÄ plugins/                    # Plugins personalizados de Airflow
‚îú‚îÄ‚îÄ mlflowdb/                   # Base de datos MLflow (volumen)
‚îú‚îÄ‚îÄ docker-compose.yml          # Orquestaci√≥n de servicios
‚îú‚îÄ‚îÄ docker-compose.yml.bk       # Backup del compose
‚îú‚îÄ‚îÄ arquitecturaAirflow.drawio.svg # Diagrama de arquitectura
‚îî‚îÄ‚îÄ README.md                   
```

---

## Workflow del DAG de Entrenamiento

El DAG `training_dag` automatiza el proceso completo de entrenamiento de modelos con integraci√≥n MLflow:

### Tareas del DAG

1. **check_run_count** üî¢
   - Verifica el n√∫mero de ejecuciones (m√°ximo 11)
   - Incrementa el contador de ejecuciones

2. **branch_first_run** üåø
   - Determina si es la primera ejecuci√≥n del DAG
   - Dirige el flujo seg√∫n el estado inicial

3. **clean_all_data** üóëÔ∏è (solo primera vez)
   - Limpia datos anteriores de la base de datos MySQL
   - Prepara el entorno para nuevos datos

4. **store_raw_data** üì•
   - Descarga el dataset desde la fuente
   - Almacena los datos en la base de datos MySQL

5. **get_raw_data** üîÑ
   - Extrae datos de la base de datos
   - Aplica transformaciones ETL b√°sicas

6. **save_clean_data** üíæ
   - Guarda datos limpios para entrenamiento
   - Prepara datos finales para el modelo

7. **train_model** ü§ñ
   - Entrena modelo Random Forest con GridSearch
   - Registra experimento en MLflow
   - Promociona mejor modelo a producci√≥n autom√°ticamente

8. **mark_done** ‚úÖ
   - Marca la primera ejecuci√≥n como completada

9. **pause_dag_if_failed** ‚è∏Ô∏è
   - Pausa el DAG si alguna tarea falla

### Flujo de Ejecuci√≥n

```
check_run_count ‚Üí branch_first_run ‚Üí [clean_all_data | skip_first_time] ‚Üí 
join_after_branch ‚Üí mark_done ‚Üí store_raw_data ‚Üí get_raw_data ‚Üí 
save_clean_data ‚Üí train_model ‚Üí pause_dag_if_failed
```

### Programaci√≥n

- **Schedule**: `timedelta(minutes=5, seconds=20)` (cada 5 minutos y 20 segundos)
- **Start Date**: 2025-10-03
- **Max Active Runs**: 11
- **Catchup**: False

---

## Modelos implementados

- **Random Forest** - Clasificador de bosques aleatorios con GridSearch
- **MLflow Integration** - Tracking autom√°tico y versionado de modelos
- **Model Registry** - Gesti√≥n centralizada con alias de producci√≥n

---

## Dataset de Cover Type

El proyecto utiliza el dataset de Cover Type para clasificaci√≥n forestal:

### Caracter√≠sticas del Dataset

- **Elevation**: Elevaci√≥n en metros
- **Aspect**: Orientaci√≥n en grados (0-360)
- **Slope**: Pendiente en grados
- **Horizontal_Distance_To_Hydrology**: Distancia horizontal a hidrolog√≠a
- **Vertical_Distance_To_Hydrology**: Distancia vertical a hidrolog√≠a
- **Horizontal_Distance_To_Roadways**: Distancia horizontal a carreteras
- **Hillshade_9am**: Sombreado a las 9 AM (0-255)
- **Hillshade_Noon**: Sombreado al mediod√≠a (0-255)
- **Hillshade_3pm**: Sombreado a las 3 PM (0-255)
- **Horizontal_Distance_To_Fire_Points**: Distancia horizontal a puntos de fuego
- **Wilderness_Area**: √Årea silvestre (Rawah, Neota, Comanche, Cache)
- **Soil_Type**: Tipo de suelo (40 tipos diferentes)

### Clases de Cover Type

| Clase | Valor num√©rico | Descripci√≥n             |
|-------|----------------|-------------------------|
| 1     | 1              | Spruce/Fir              |
| 2     | 2              | Lodgepole Pine          |
| 3     | 3              | Ponderosa Pine          |
| 4     | 4              | Cottonwood/Willow       |
| 5     | 5              | Aspen                   |
| 6     | 6              | Douglas-fir             |
| 7     | 7              | Krummholz               |

---
## Desarrollo

Para desarrollo y debugging:

- **Ejecutar servicios**: `docker-compose up --build` para iniciar todos los servicios
- **Monitorear Airflow**: Acceder a 
**URL**: http://10.43.100.102:8080 (usuario: airflow, contrase√±a: airflow)
- **Monitorear MLflow**: Acceder a **URL**: http://10.43.100.99:8003/ para ver experimentos
- **Interfaz Gradio**: Acceder a http://10.43.100.102:8014 para predicciones interactivas
- **MinIO Console**: Acceder a http://10.43.100.99:8000 (admin/supersecret) para artefactos
- **Ejecutar DAGs**: El DAG `training_dag` se ejecuta autom√°ticamente cada 5 minutos
- **Ver logs**: Monitorear el progreso de las tareas en tiempo real
- **Modificar c√≥digo**: Los cambios se reflejan autom√°ticamente con hot reload
- **Modelos**: Los modelos se almacenan en MLflow y MinIO
- **Base de datos**: Conectar a MySQL en 10.43.100.86:8005 (training) y http://10.43.100.99:8004 (mlflow)

---
## Notas de la versi√≥n

- **MLflow Integration**: Tracking autom√°tico de experimentos y gesti√≥n de modelos
- **Model Registry**: Sistema centralizado de versionado con alias de producci√≥n
- **MinIO Storage**: Almacenamiento S3-compatible para artefactos de MLflow
- **Gradio Interface**: Aplicaci√≥n web interactiva para predicciones
- **Airflow**: Orquestaci√≥n completa con DAGs automatizados cada 5 minutos
- **Base de datos**: MySQL dual para datos de entrenamiento y metadatos MLflow
- **API**: Servicio FastAPI con integraci√≥n MLflow para predicciones
- **Automatizaci√≥n**: Entrenamiento y promoci√≥n autom√°tica de modelos
- **Monitoreo**: Interfaces web para Airflow, MLflow, MinIO y Gradio

---

## Gu√≠a para Capturas de Pantalla

Para documentar que todo funciona correctamente, sigue esta gu√≠a para tomar capturas de pantalla de todos los componentes:

### 1. Verificaci√≥n de Servicios Docker

```bash
# Captura del estado de contenedores
docker-compose ps
```

**Servicios de Docker Compose ejecutandose**
![Alt text](./imgs/dockerAll.png)

### 2. Airflow Webserver

**URL**: http://10.43.100.102:8080
**Credenciales**: airflow / airflow

- P√°gina principal de Airflow con DAGs listados
![Alt text](./imgs/airflowMainPage.png)
- DAG `training_dag` activo y ejecut√°ndose
![Alt text](./imgs/DAGRunning.png)
- Vista de tareas del DAG con estados (success/failed)
![Alt text](./imgs/DAGTasks.png)
- Logs de la tarea train_model
![Alt text](./imgs/TaskLog.png)

### 3. MLflow Tracking Server

**URL**: http://10.43.100.99:8003/

- P√°gina principal de MLflow
![Alt text](./imgs/mlMain.png)
- Secci√≥n "Experiments" mostrando `random_forest_experiment`
![Alt text](./imgs/mlExperiment.png)
- Vista de runs con m√©tricas y par√°metros
![Alt text](./imgs/mlStatistics.png)
- Secci√≥n "Models" mostrando `random-forest-regressor`
![Alt text](./imgs/mlModels.png)
- Detalles del modelo con alias "prod"
![Alt text](./imgs/mlProd.png)

### 4. MinIO Console

**URL**: http://10.43.100.99:8000
**Credenciales**: admin / supersecret

- Dashboard principal de MinIO
![Alt text](./imgs/Minioinicio.png)
- Bucket `mlflows` con artefactos almacenados
![Alt text](./imgs/Minioartefactos.png)
- Contenido del bucket mostrando modelos y logs
![Alt text](./imgs/MinioBuckets.png)

### 5. API de Predicci√≥n

**URL**: http://10.43.100.102:8012

- Documentaci√≥n autom√°tica en `/docs`
![Alt text](./imgs/apiDocs.png)
- Endpoint `/predict` con ejemplo de request/response
![Alt text](./imgs/apiPredict.png)

### 6. Aplicaci√≥n Web Gradio

**URL**: http://10.43.100.102:8014

- Interfaz principal con formularios
![Alt text](./imgs/gradio.png)

- Ejemplo de predicci√≥n con datos de entrada
![Alt text](./imgs/predictGradio.png)

- Secci√≥n de ejemplos predefinidos
![Alt text](./imgs/gradioExamples.png)


### 7. Base de Datos MySQL

**Conexi√≥n**: 10.43.100.86:8005 (training) y http://10.43.100.99:8004 (mlflow)

- Conexi√≥n exitosa a base de datos de entrenamiento
- Tablas con datos de entrenamiento
- Conexi√≥n a base de datos MLflow
- Tablas de metadatos de MLflow

### 8. Logs del Sistema

```bash
# Logs de Airflow
docker-compose logs airflow-webserver

# Logs de MLflow
docker-compose logs mlflow

# Logs de API
docker-compose logs prediction
```

- Logs de Airflow mostrando ejecuci√≥n de DAG
![Alt text](./imgs/afLogs.png)
- Logs de MLflow mostrando tracking de experimentos
![Alt text](./imgs/mlLogs.png)
- Logs de API mostrando requests de predicci√≥n
![Alt text](./imgs/apiLogs.png)

- Artefactos de MLflow en MinIO

### 9. Flujo Completo de Predicci√≥n

1. DAG ejecut√°ndose en Airflow
![Alt text](./imgs/dagRun.png)
2. Modelo entrenado en MLflow

3. Predicci√≥n exitosa en API
4. Interfaz Gradio funcionando
5. Datos almacenados en MySQL


